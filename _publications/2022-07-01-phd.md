---
title: "Statistical analysis of the evolution of extreme claims for bodily risk cover."
collection: Paper
permalink: /publication/2022-07-01-phd
excerpt: 'The objective of this thesis is to show how the richness of the available data on insurance claims can be used to significantly improve the prediction of the final amount of a claim (or its outcome, when we are interested in the classification of a claim according to its level of severity). To process such a large volume of data - some of which are textual data, not very common in insurance - we use statistical learning techniques (in particular deep neural networks such as Convolutional Neural Networks or Long Short Term Memory networks) both as predictors and as information extractors. The study of bodily claims requires a specific treatment due to their characteristics and the extreme volatility of their cost. Extreme Value Theory tools allowed us to analyze the tail distribution of the claim's amount, but also to determine a severity threshold. Another specificity of our approach was to take into account the temporal flow of claims, which is particularly important when we are interested in a branch of insurance with a long development such as third party liability. During this thesis, we used several times IPCW (Inverse-Probability-of-Censoring Weighting) weights in order to deal with the phenomenon of censorship which makes the information available incomplete.'
date: 2022-07-01
venue: 'Sorbonne University'
citation: 'Isaac Cohen Sabban. Analyse statistique de l'évolution des sinistres graves pour une garantie risque corporel. Mathématiques. Sorbonne Université, 2022. Français.'
---
## Statistical analysis of the evolution of extreme claims for bodily risk cover*

The objective of this thesis is to show how the richness of the available data on insurance claims can be used to significantly improve the prediction of the final amount of a claim (or its outcome, when we are interested in the classification of a claim according to its level of severity). To process such a large volume of data - some of which are textual data, not very common in insurance - we use statistical learning techniques (in particular deep neural networks such as Convolutional Neural Networks or Long Short Term Memory networks) both as predictors and as information extractors. The study of bodily claims requires a specific treatment due to their characteristics and the extreme volatility of their cost. Extreme Value Theory tools allowed us to analyze the tail distribution of the claim's amount, but also to determine a severity threshold. Another specificity of our approach was to take into account the temporal flow of claims, which is particularly important when we are interested in a branch of insurance with a long development such as third party liability. During this thesis, we used several times IPCW (Inverse-Probability-of-Censoring Weighting) weights in order to deal with the phenomenon of censorship which makes the information available incomplete.
